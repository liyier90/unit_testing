\documentclass[english,10pt,aspectratio=169,t]{beamer}

\input{include/packagecommand}
\input{include/definition}

\def\presentationtitle{\textbf{
  Spending less time bug fixing by \\
  spending more time unit testing
}}

\title{\large\presentationtitle}
\author{\textbf{
  <Name>
}}
\date{}

\begin{document}

\input{include/codelistings}

\begin{frame}
  \titlepage
\end{frame}

% To begin with a quote from the author, "There's much more to unit testing than
% the act of writing tests." Hopefully this presentation will be able to get you
% to think more about how to craft unit tests.
\begin{frame}
  \vfill
  \begin{quote}
    There's much more to unit testing than the act of writing tests.
    \begin{flushright}
      \tiny{---Khorikov, \textup{Unit Testing Principles, Practices, and Patterns}, 3}
    \end{flushright}
  \end{quote}
  \vfill
\end{frame}

% The goal of unit testing is to enable sustainable growth of the software
% project. The figure below show the growth dynamics of a typical project without
% tests. You start off quick, completing user stories after user stories, without
% having to "waste" writing these pesky tests.
% But eventually progress slows to a halt, the code base has grown complex and
% disorganized, fixing one bug introduces several others, and changing one part
% of the software breaks several others. And it's hard to bring it back to
% stability.
% This is where tests help, they help detect regressions and ensure existing
% functionalities work even after refactoring or introducing new features.
\begin{frame}{The goal of unit testing}
  To enable \textbf{sustainable} growth of software project.
  \begin{columns}[T]
    \begin{column}{0.5\textwidth}
      \includegraphics[width=\textwidth]{images/vs_no_test.png}
    \end{column}
    \begin{column}{0.5\textwidth}
    \end{column}
  \end{columns}
\end{frame}

% But it's not enough to just write tests. Badly written tests still result in
% the same picture. They help slow down the initial decline in development speed
% but doesn't really change much overall. Before we look at what makes a good unit
% test, let's first look at code coverage metrics which can help you gauge if you
% are testing enough.
\begin{frame}{The goal of unit testing}
  To enable \textbf{sustainable} growth of software project.
  \begin{columns}[T]
    \begin{column}{0.5\textwidth}
      \includegraphics[width=\textwidth]{images/vs_no_test.png}
    \end{column}
    \begin{column}{0.5\textwidth}
      \includegraphics[width=\textwidth]{images/vs_bad_test.png}
    \end{column}
  \end{columns}
\end{frame}

% The common belief is that the higher the coverage number, the better the test
% suite. Unfortunately, it's not that simple. While 10% is a good indication
% that you aren't testing enough, 100% coverage doesn't guarantee you have a
% good quality test suite. We take a look at a few coverage metrics to see why
% this is so.
% We will discuss 4 types of coverage metrics. Path and condition coverage are
% struck out because while they're nice to think about, they're impractical to
% actually implement.
% < describe the code and coverage stats > 
\begin{frame}{Coverage metrics}
  \focus{Statement} vs Branch vs \sout{Path} vs \sout{Condition}
  \begin{columns}[T]
    \begin{column}[]{0.6\textwidth}
      \begin{minipage}{\linewidth}
        \coveragecode
      \end{minipage}
    \end{column}
    \begin{column}[]{0.4\textwidth}
      \begin{flalign*}
        &\frac{Number\ of\ statements\ executed}{Total\ number\ of\ statements}\\
        \approx\ &67 \%
      \end{flalign*}
    \end{column}
  \end{columns}
\end{frame}

% One simple trick to improve our statement coverage metric to refactor the
% function into a conditional expression. Now we get 100% statement coverage
% without having to write any extra tests. This just shows how easy it is to game
% the coverage metrics.
\begin{frame}{Coverage metrics}
  \focus{Statement} vs Branch vs \sout{Path} vs \sout{Condition}
  \begin{columns}[T]
    \begin{column}[]{0.6\textwidth}
      \begin{minipage}{\linewidth}
        \coveragecodetwo
      \end{minipage}
    \end{column}
    \begin{column}[]{0.4\textwidth}
      \begin{flalign*}
        &\frac{Number\ of\ statements\ executed}{Total\ number\ of\ statements}\\
        =\ &100 \%
      \end{flalign*}
    \end{column}
  \end{columns}
\end{frame}

% Branch coverage considers how many control structures are traversed by at least
% one test in the test suite. And reports 50% coverage no matter how we refactor
% the function.
\begin{frame}{Coverage metrics}
  Statement vs \focus{Branch} vs \sout{Path} vs \sout{Condition}
  \begin{columns}[T]
    \begin{column}[]{0.6\textwidth}
      \begin{minipage}{\linewidth}
        \coveragecodetwo
      \end{minipage}
    \end{column}
    \begin{column}[]{0.4\textwidth}
      \begin{flalign*}
        &\frac{Branches\ traversed}{Total\ number\ of\ branches}\\
        =\ &50 \%
      \end{flalign*}
    \end{column}
  \end{columns}
\end{frame}

% To help visualize this metric, the flowchart shows the possible paths of the
% function. And the test_fizzbuzz() function only traversed through one of them.
\begin{frame}{Coverage metrics}
  Statement vs \focus{Branch} vs \sout{Path} vs \sout{Condition}
  \begin{columns}[T]
    \begin{column}[]{0.6\textwidth}
      \begin{minipage}{\linewidth}
        \coveragecodetwo
      \end{minipage}
    \end{column}
    \begin{column}[]{0.4\textwidth}
      \begin{tikzpicture}[node distance=2cm]
        \node (start) [startstop] {\small{Start}};
        \node (decision)
          [decision, below of=start, text width=1cm, align=center]
          {\scriptsize{Indivisible by 3 and 5?}};
        \node (out1) [io, below of=decision] {\small{True}};
        \node (out2) [io, right of=decision, xshift=1cm] {\small{some\_var}};
        \draw [arrow] (start) -- (decision);
        \draw [arrow] (decision) -- node[anchor=east] {yes} (out1);
        \draw [arrow] (decision) -- node[anchor=south] {no} (out2);
      \end{tikzpicture}
    \end{column}
  \end{columns}
\end{frame}

% This function has 3 if conditions each returning a different number. Branch
% coverage requires 6 test cases. But does achieving 100% branch coverage
% ensure that this function won't crash? What happens when all 3 conditions
% evaluate to False? Path coverage ensures all paths are covered. It will test
% path BDF and catch the bug. Although this will give you a very comprehensive
% coverage of your code, 100% path coverage is impractical to aim for in reality.
\begin{frame}{Coverage metrics}
  Statement vs Branch vs \focus{\sout{Path}} vs \sout{Condition}
  \begin{columns}[T]
    \begin{column}[]{0.5\textwidth}
      \begin{minipage}{\linewidth}
        \coveragecodebranch
        Possible paths:

        ACE, ACF, ADE, ADF, BCE, BCF, BDE, BDF
      \end{minipage}
    \end{column}
    \begin{column}[]{0.5\textwidth}
      \begin{tikzpicture}[node distance=1.3cm]
        \node (start) [startstop] {\small{Start}};
        \node (dec1) [decision, below of=start, aspect=3, yshift=1mm]
          {\scriptsize{cond\_1?}};
        \node (out11) [io, left of=dec1, xshift=-1.75cm, label={A}]
          {\small{num = 1}};
        \node (out12) [io, right of=dec1, xshift=1cm, label={B}] {\small{pass}};
        \node (dec2) [decision, below of=dec1, aspect=3]
          {\scriptsize{cond\_2?}};
        \node (out21) [io, left of=dec2, xshift=-1.75cm, label={C}]
          {\small{num = 2}};
        \node (out22) [io, right of=dec2, xshift=1cm, label={D}] {\small{pass}};
        \node (dec3) [decision, below of=dec2, aspect=3]
          {\scriptsize{cond\_3?}};
        \node (out31) [io, left of=dec3, xshift=-1.75cm, label={E}]
          {\small{num = 3}};
        \node (out32) [io, right of=dec3, xshift=1cm, label={F}] {\small{pass}};
        \node (end) [startstop, below of=dec3] {\small{End}};
        \draw [arrow] (start) -- (decision);
        \draw [arrow] (dec1) -- node[anchor=south] {yes} (out11);
        \draw [arrow] (dec1) -- node[anchor=south] {no} (out12);
        \draw [arrow] (out11) |- ++(0, -5mm) -| (dec2);
        \draw [arrow] (out12) |- ++(0, -5mm) -| (dec2);
        \draw [arrow] (dec2) -- node[anchor=south] {yes} (out21);
        \draw [arrow] (dec2) -- node[anchor=south] {no} (out22);
        \draw [arrow] (out21) |- ++(0, -5mm) -| (dec3);
        \draw [arrow] (out22) |- ++(0, -5mm) -| (dec3);
        \draw [arrow] (dec3) -- node[anchor=south] {yes} (out31);
        \draw [arrow] (dec3) -- node[anchor=south] {no} (out32);
        \draw [arrow] (out31) |- ++(0, -5mm) -| (end);
        \draw [arrow] (out32) |- ++(0, -5mm) -| (end);
      \end{tikzpicture}
    \end{column}
  \end{columns}
\end{frame}

% The goal of condition coverage is to check individual outcomes for each logical
% condition. Branch coverage requires only 2 test cases, but condition coverage
% requires 4. Aiming for 100% conditional coverage is also impractical.
% Say, a test suite achieved 100% on all coverage metrics for this is_fizzbuzz()
% function, does that mean the test suite is guaranteed to cover all use cases
% catch all bugs? What if the user supplies a string instead of a int?
\begin{frame}{Coverage metrics}
  Statement vs Branch vs \sout{Path} vs \focus{\sout{Condition}}
  \begin{columns}[T]
    \begin{column}[]{0.5\textwidth}
      \begin{minipage}{\linewidth}
        \coveragecode
      \end{minipage}
    \end{column}
    \begin{column}[]{0.5\textwidth}
      \begin{center}
        \begin{tabular}{ ccc }
          \hline
          \texttt{num \% 3} & \texttt{num \% 5} & \texttt{num \% 3 and num \% 5} \\
          \hline
          True & True & True \\
          True & False & False \\
          False & True & False \\
          False & False & False \\
          \hline
        \end{tabular}
      \end{center}
    \end{column}
  \end{columns}
\end{frame}

\begin{frame}
  \vfill
  \begin{quote}
    [C]overage metrics are a good negative indicator, but a bad positive one.
    \begin{flushright}
      \tiny{---Khorikov, \textup{Unit Testing Principles, Practices, and Patterns}, 15}
    \end{flushright}
  \end{quote}
  \vfill
\end{frame}

\begin{frame}{Definition of a unit test}
  \begin{itemize}
    \item Verifies a small piece of code,
    \item Does it quickly, and
    \item Does it in an isolated manner.
  \end{itemize}

  An integration test is a test that doesn't meet one of these criteria. End-to-end
  tests are a subset of integration tests and usually include more dependencies.
\end{frame}

% A simple, uniform structure. Once you get used to it, it become easy to read and
% understand any test. This will reduce maintenance cost.
\begin{frame}{Anatomy of a unit test}
  The AAA (3A) pattern, also Given-When-Then pattern.

  \begin{columns}[T]
    \begin{column}[]{0.5\textwidth}
      \begin{minipage}{\linewidth}
        \aaapattern
      \end{minipage}
    \end{column}
    \begin{column}[]{0.5\textwidth}
      \begin{itemize}
        \item In \textit{Arrange}, bring the system under test (SUT) to the a
        desired state
        \item In \textit{Act}, call the method on the SUT, pass the prepared
        dependencies, and capture the output (if any).
        \item In \textit{Assert}, verify the outcome. The outcome could be the
        return value, the final state of the SUT, or the methods the SUT called
        on its collaborators.
      \end{itemize}
    \end{column}
  \end{columns}
\end{frame}

% If you have multiple act and assert, this is no longer a unit test but an
% integration test. Refactor and extract each 'act" into a test of its own. But
% having multiple act sections is an appropriate optimization technique for
% integration tests.
\begin{frame}{Things to avoid for unit tests}
  \begin{columns}[T]
    \begin{column}[]{0.5\textwidth}
      \begin{minipage}{\linewidth}
        \begin{center}
          \begin{tikzpicture}[node distance=1.3cm]
            \node (arrange1) [startstop] {\small{Arrange the test}};
            \node (act1) [startstop, below of=arrange1] {\small{Act}};
            \node (assert1) [startstop, below of=act1] {\small{Assert}};
            \node (act2) [startstop, below of=assert1] {\small{Act some more}};
            \node (assert2) [startstop, below of=act2] {\small{Assert again}};
            \draw [arrow] (arrange1) -- (act1);
            \draw [arrow] (act1) -- (assert1);
            \draw [arrow] (assert1) -- (act2);
            \draw [arrow] (act2) -- (assert2);
          \end{tikzpicture}
        \end{center}
      \end{minipage}
    \end{column}
    \begin{column}[]{0.5\textwidth}
      \begin{itemize}
        \item Avoid multiple arrange, act, and assert sections.
      \end{itemize}
    \end{column}
  \end{columns}
\end{frame}

% Having if statements is also an anti-pattern. If you have if statements in the
% act section, if indicates the test is verifies too many things at once.
% The code listing on the left also demonstrates why if statements should be
% avoided in tests. Turns out, cap.records has only 4 elements, i == 4 never
% got verified.
\begin{frame}{Things to avoid for unit tests}
  \begin{columns}[T]
    \begin{column}[]{0.5\textwidth}
      \begin{minipage}{\linewidth}
        \avoidifpkd
      \end{minipage}
    \end{column}
    \begin{column}[]{0.5\textwidth}
      \begin{itemize}
        \item Avoid multiple arrange, act, and assert sections.
        \item Avoid \texttt{if} statements. 
      \end{itemize}
    \end{column}
  \end{columns}
\end{frame}

% Hurts readability, why is there valid and invalid next to each other?
% What if we refactor is_delivery_valid(), do we need to rename all the tests?
% Additional cognitive load to figure out what behavior this test is testing.
\begin{frame}{Naming a unit test}
  \begin{columns}[T]
    \begin{column}[]{0.55\textwidth}
      \begin{minipage}{\linewidth}
        \rigidname
      \end{minipage}
    \end{column}
    \begin{column}[]{0.45\textwidth}
      \begin{itemize}
        \item A rigid convention such as \texttt{<method>\_<scenario>\_<expected>}
        isn't as helpful as plain English
      \end{itemize}
    \end{column}
  \end{columns}
\end{frame}

\begin{frame}{Naming a unit test}
  \begin{columns}[T]
    \begin{column}[]{0.55\textwidth}
      \begin{minipage}{\linewidth}
        \rigidname
        \verbosename
      \end{minipage}
    \end{column}
    \begin{column}[]{0.45\textwidth}
      \begin{itemize}
        \item A rigid convention such as \texttt{<method>\_<scenario>\_<expected>}
        isn't as helpful as plain English
        \item Should not be too verbose
      \end{itemize}
    \end{column}
  \end{columns}
\end{frame}

% "considered" can be removed without losing meaning. "should be" makes this sound
% like a wish, can be replaced with "is" to represent that this is a fact about
% the software we're developing. There is not need to avoid basic English grammar,
% adding the article "a" helps this read like a normal sentence.
\begin{frame}{Naming a unit test}
  \begin{columns}[T]
    \begin{column}[]{0.55\textwidth}
      \begin{minipage}{\linewidth}
        \rigidname
        \verbosename
        \concisename
      \end{minipage}
    \end{column}
    \begin{column}[]{0.45\textwidth}
      \begin{itemize}
        \item A rigid convention such as \texttt{<method>\_<scenario>\_<expected>}
        isn't as helpful as plain English
        \item Should not be too verbose
      \end{itemize}
    \end{column}
  \end{columns}
\end{frame}

\begin{frame}{Parametrizing tests}
  \footnotesize{\textit{Parametrization, also spelled parameterization, parametrisation
  or parameterisation, is the process of defining or choosing parameters.} --- Wikipedia}
  \begin{columns}[T]
    \begin{column}[]{0.5\textwidth}
      \begin{minipage}{\linewidth}
        \includegraphics[width=\textwidth]{images/parametrized_tests.png}
      \end{minipage}
    \end{column}
    \begin{column}[]{0.5\textwidth}
      \begin{itemize}
        \item The number of tests can become unmanageable if each component/behavior
        of the application is tested with its own test.
        \item Some (similar) behaviors can be grouped into a single test using
        parametrization.
      \end{itemize}
    \end{column}
  \end{columns}
\end{frame}

\begin{frame}{Parametrizing tests}
  \begin{minipage}{\textwidth}
    Behavior: The soonest allowed delivery date is two days from now. 
  \end{minipage}
  \vfill
  \begin{minipage}{\textwidth}
    In addition to \texttt{test\_delivery\_with\_a\_past\_date\_is\_invalid}, we
    need to add three more:

    \additionalbehavior

    This would result in four test methods, with the only difference between them
    being the delivery date.
  \end{minipage}
\end{frame}

% This comes at a cost, it's now hard to figure out what facts the test method
% represent.
\begin{frame}{Parametrizing tests}
  \begin{minipage}{\textwidth}
    Behavior: The soonest allowed delivery date is two days from now. 
  \end{minipage}
  \begin{columns}[T]
    \begin{column}{0.5\textwidth}
      \begin{minipage}{\textwidth}
        \parametrizeall
      \end{minipage}
    \end{column}
    \begin{column}{0.5\textwidth}
      \begin{itemize}
        \item Significantly reduce the amount of test code
      \end{itemize}
    \end{column}
  \end{columns}
\end{frame}

\begin{frame}{Parametrizing tests (meaningfully)}
  \begin{minipage}{\textwidth}
    Behavior: The soonest allowed delivery date is two days from now. 
  \end{minipage}
  \begin{columns}[T]
    \begin{column}{0.5\textwidth}
      \begin{minipage}{\textwidth}
        \parametrizesome
      \end{minipage}
    \end{column}
    \begin{column}{0.5\textwidth}
      \begin{itemize}
        \item Significantly reduce the amount of test code
        \item Do not ``over parametrize'' if the scenarios are complicated
      \end{itemize}
    \end{column}
  \end{columns}
\end{frame}

\begin{frame}{Using an assertion library (optional)}
  \begin{minipage}{\textwidth}
    An assertion library like \texttt{assertpy} can improve test readability by
    making the assert section read like plain English.
  \end{minipage}
  \begin{columns}[T]
    \begin{column}{0.5\textwidth}
      \begin{minipage}{\textwidth}
        \assertionlibrary
      \end{minipage}
    \end{column}
    \begin{column}{0.5\textwidth}
      \begin{itemize}
        \item Introduces additional dependencies
      \end{itemize}
    \end{column}
  \end{columns}
\end{frame}

\begin{frame}{Using an assertion library (optional)}
  \begin{minipage}{\textwidth}
    An assertion library like \texttt{assertpy} can improve test readability by
    making the assert section read like plain English.
  \end{minipage}
  \begin{columns}[T]
    \begin{column}{0.5\textwidth}
      \begin{minipage}{\textwidth}
        \assertionlibrary

        Bonus: \texttt{Chai} assertion library
        \chailibrary
      \end{minipage}
    \end{column}
    \begin{column}{0.5\textwidth}
      \begin{itemize}
        \item Introduces additional dependencies
      \end{itemize}
    \end{column}
  \end{columns}
\end{frame}
\end{document}
